{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**LEITURA DOS DADOS DO SUSTAIN BENCH**"
      ],
      "metadata": {
        "id": "ppkckTGwFLH7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "nLuY6bhQDxmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442dc408-fb43-4eac-855f-a76f13f71b58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes dos arrays:\n",
            "Hist: (247, 32, 32, 9)\n",
            "NDVI: (247, 32)\n",
            "Locs: (247,)\n",
            "Years: (247,)\n",
            "Keys: (247,)\n",
            "Yields: (247,)\n",
            "\n",
            "Primeiras linhas:\n",
            "     hist_0    hist_1    hist_2   hist_3    hist_4    hist_5    hist_6  \\\n",
            "0  0.000000  0.000270  0.000025  0.00000  0.000037  0.000061  0.000061   \n",
            "1  0.000000  0.000945  0.000000  0.00000  0.000065  0.000126  0.000189   \n",
            "2  0.000673  0.000657  0.000000  0.00003  0.000547  0.000437  0.002556   \n",
            "3  0.000000  0.000538  0.000107  0.00000  0.000401  0.000000  0.000000   \n",
            "4  0.000000  0.000343  0.000000  0.00000  0.000144  0.000274  0.000480   \n",
            "\n",
            "   hist_7  hist_8    hist_9  ...   ndvi_27   ndvi_28   ndvi_29   ndvi_30  \\\n",
            "0     0.0     0.0  0.000000  ...  0.698605  0.640461  0.566693  0.645517   \n",
            "1     0.0     0.0  0.000000  ...  0.822922  0.786009  0.720077  0.574686   \n",
            "2     0.0     0.0  0.000485  ...  0.637951  0.673795  0.624429  0.531740   \n",
            "3     0.0     0.0  0.000000  ...  0.729741  0.787198  0.824194  0.805108   \n",
            "4     0.0     0.0  0.000000  ...  0.699269  0.692859  0.646264  0.760457   \n",
            "\n",
            "    ndvi_31   lat   lon  year                                    region_id  \\\n",
            "0  0.605391  None  None  2008  triangulo mineiroalto paranaiba_brasil_2008   \n",
            "1  0.662463  None  None  2011                            assis_brasil_2011   \n",
            "2  0.597713  None  None  2007                       sul goiano_brasil_2007   \n",
            "3  0.793112  None  None  2011    centro ocidental riograndense_brasil_2011   \n",
            "4  0.579717  None  None  2011            oriental do tocantins_brasil_2011   \n",
            "\n",
            "   yield  \n",
            "0  2.941  \n",
            "1  3.100  \n",
            "2  2.737  \n",
            "3  2.753  \n",
            "4  3.030  \n",
            "\n",
            "[5 rows x 9253 columns]\n",
            "\n",
            "Colunas totais:\n",
            "Index(['hist_0', 'hist_1', 'hist_2', 'hist_3', 'hist_4', 'hist_5', 'hist_6',\n",
            "       'hist_7', 'hist_8', 'hist_9',\n",
            "       ...\n",
            "       'ndvi_27', 'ndvi_28', 'ndvi_29', 'ndvi_30', 'ndvi_31', 'lat', 'lon',\n",
            "       'year', 'region_id', 'yield'],\n",
            "      dtype='object', length=9253)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# -----------------------------\n",
        "# Função para carregar um .npz\n",
        "# -----------------------------\n",
        "def load_npz_array(path):\n",
        "    data = np.load(path, allow_pickle=True) # Adiciona allow_pickle=True\n",
        "    return data[data.files[0]]  # pega o array interno\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Carregar todos os arquivos de treino\n",
        "# -----------------------------\n",
        "X_hist = load_npz_array(\"train_hists.npz\")\n",
        "X_ndvi = load_npz_array(\"train_ndvi.npz\")\n",
        "X_loc = load_npz_array(\"train_locs.npz\")\n",
        "X_year = load_npz_array(\"train_years.npz\")\n",
        "X_key = load_npz_array(\"train_keys.npz\")\n",
        "y = load_npz_array(\"train_yields.npz\")\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Mostrar shapes\n",
        "# -----------------------------\n",
        "print(\"Shapes dos arrays:\")\n",
        "print(\"Hist:\", X_hist.shape)\n",
        "print(\"NDVI:\", X_ndvi.shape)\n",
        "print(\"Locs:\", X_loc.shape)\n",
        "print(\"Years:\", X_year.shape)\n",
        "print(\"Keys:\", X_key.shape)\n",
        "print(\"Yields:\", y.shape)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Montar um DataFrame para visualização\n",
        "# -----------------------------\n",
        "\n",
        "# Hist tem muitas colunas → renomear\n",
        "X_hist_reshaped = X_hist.reshape(X_hist.shape[0], -1) # Achata as dimensões restantes\n",
        "hist_cols = [f\"hist_{i}\" for i in range(X_hist_reshaped.shape[1])]\n",
        "df_hist = pd.DataFrame(X_hist_reshaped, columns=hist_cols)\n",
        "\n",
        "# NDVI também\n",
        "ndvi_cols = [f\"ndvi_{i}\" for i in range(X_ndvi.shape[1])]\n",
        "df_ndvi = pd.DataFrame(X_ndvi, columns=ndvi_cols)\n",
        "\n",
        "\n",
        "# Para corrigir o ValueError, vamos criar um DataFrame com duas colunas de None.\n",
        "df_loc = pd.DataFrame({'lat': X_loc, 'lon': X_loc})\n",
        "\n",
        "df_year = pd.DataFrame(X_year, columns=[\"year\"])\n",
        "df_key = pd.DataFrame(X_key, columns=[\"region_id\"])\n",
        "df_y = pd.DataFrame(y, columns=[\"yield\"])\n",
        "\n",
        "# Junta tudo\n",
        "df = pd.concat([df_hist, df_ndvi, df_loc, df_year, df_key, df_y], axis=1)\n",
        "\n",
        "print(\"\\nPrimeiras linhas:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nColunas totais:\")\n",
        "print(df.columns)\n",
        "\n",
        "#printa so as locs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ACHAR INFORMAÇOES ESPACIAIS**\n",
        "\n",
        "O conjunto de dados carece de Latitude e Longitude, o que é um impedimento crucial.\n",
        "\n",
        "A Solução é: Derivar o Lat/Long do REGION_ID usando o nome do município e a ferramenta Geopy.\n",
        "\n",
        "A Justificativa Principal é: Embora as features existentes já sejam climáticas históricas, a adição do Lat/Long não só oferece um contexto geográfico direto, mas, mais importante, serve como chave de agregação para incorporar dados climáticos externos mais ricos e detalhados (ex: interpolação de dados do INMET), maximizando assim o poder preditivo do modelo."
      ],
      "metadata": {
        "id": "mp_KZfw-KuVt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57938312",
        "outputId": "6425c779-3510-4945-d7c2-83f44b345d1b"
      },
      "source": [
        "# Instala a biblioteca geopy para geocodificação\n",
        "!pip install geopy"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopy in /usr/local/lib/python3.12/dist-packages (2.4.1)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.12/dist-packages (from geopy) (2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1237a04",
        "outputId": "2d3471ac-2a75-48e1-bb90-5b49ff354ea4"
      },
      "source": [
        "from geopy.geocoders import Nominatim\n",
        "from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
        "import time\n",
        "\n",
        "geolocator = Nominatim(user_agent=\"my-geocoder-app\")\n",
        "\n",
        "def get_lat_lon(region_id):\n",
        "    try:\n",
        "        # Extrai o nome da região (removendo o ano e '_brasil_')\n",
        "        region_name = region_id.split('_brasil_')[0].replace('_', ' ').strip()\n",
        "        location = geolocator.geocode(region_name + \", Brasil\", timeout=5) # Adiciona \"Brasil\" para melhorar a precisão\n",
        "        if location:\n",
        "            return location.latitude, location.longitude\n",
        "        else:\n",
        "            return None, None\n",
        "    except (GeocoderTimedOut, GeocoderServiceError):\n",
        "        # Lida com erros de timeout ou serviço\n",
        "        time.sleep(1) # Espera um pouco antes de tentar novamente\n",
        "        return get_lat_lon(region_id) # Tenta novamente\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao geocodificar {region_id}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Aplica a função para obter as coordenadas\n",
        "df['new_lat'], df['new_lon'] = zip(*df['region_id'].apply(get_lat_lon))\n",
        "\n",
        "print(\"Valores únicos de new_lat e new_lon (amostra):\")\n",
        "print(df[['new_lat', 'new_lon']].head())\n",
        "print(f\"\\nNúmero de NAs em new_lat: {df['new_lat'].isnull().sum()}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores únicos de new_lat e new_lon (amostra):\n",
            "     new_lat    new_lon\n",
            "0        NaN        NaN\n",
            "1 -22.662089 -50.420623\n",
            "2 -17.986969 -49.376600\n",
            "3        NaN        NaN\n",
            "4        NaN        NaN\n",
            "\n",
            "Número de NAs em new_lat: 166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6ab13ea9",
        "outputId": "ec3efbb8-2ff5-41dd-a430-6c602ded7fe8"
      },
      "source": [
        "# Atualiza as colunas 'lat' e 'lon' com as novas coordenadas\n",
        "df['lat'] = df['new_lat']\n",
        "df['lon'] = df['new_lon']\n",
        "\n",
        "# Remove as colunas temporárias 'new_lat' e 'new_lon'\n",
        "df = df.drop(columns=['new_lat', 'new_lon'])\n",
        "\n",
        "print(\"Colunas 'lat' e 'lon' atualizadas. Primeiras linhas:\")\n",
        "print(df[['lat', 'lon']].head())\n",
        "print(f\"\\nNúmero de NAs restantes em lat: {df['lat'].isnull().sum()}\")\n",
        "print(f\"Número de NAs restantes em lon: {df['lon'].isnull().sum()}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colunas 'lat' e 'lon' atualizadas. Primeiras linhas:\n",
            "         lat        lon\n",
            "0        NaN        NaN\n",
            "1 -22.662089 -50.420623\n",
            "2 -17.986969 -49.376600\n",
            "3        NaN        NaN\n",
            "4        NaN        NaN\n",
            "\n",
            "Número de NAs restantes em lat: 166\n",
            "Número de NAs restantes em lon: 166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementaçao do Modelo"
      ],
      "metadata": {
        "id": "R1yDYWOFNNiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "!pip install streamlit pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-HoxgpwXNYHK",
        "outputId": "6b5a0d61-7cdf-4e56-d892-eb5423e66a50"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.52.1)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.29.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Coloque seu token aqui\n",
        "ngrok.set_auth_token(\"36RRGdxtdsr6l1S2mMDLnCrDNf2_2pxhtaKfNrdsZJAUEM8oq\")"
      ],
      "metadata": {
        "id": "cpCfRtrcSJF3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"Teste Streamlit no Colab\")\n",
        "st.write(\"Se você está vendo isso, funcionou!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZabJe2VRYW_",
        "outputId": "1299204b-f99b-40d3-fbee-4f89f0505419"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_pickle(\"dados.pkl\")\n"
      ],
      "metadata": {
        "id": "Ux1QOWwJRU36"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# --------------------------\n",
        "# Carregar DataFrame salvo\n",
        "# --------------------------\n",
        "st.title(\"Modelos de Predição de Produtividade de Soja\")\n",
        "\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    return pd.read_pickle(\"dados.pkl\")\n",
        "\n",
        "df = load_data()\n",
        "st.write(\"Dimensões do dataset:\", df.shape)\n",
        "st.write(df.head())\n",
        "\n",
        "# --------------------------\n",
        "# 1. Seleção de alvo e split\n",
        "# --------------------------\n",
        "\n",
        "#corta os features com hist da seleçao\n",
        "available_targets = [\"yield\"]\n",
        "\n",
        "# O 'yield' será sempre o target padrão, então o índice é 0\n",
        "default_target_index = 0\n",
        "\n",
        "target_col = st.selectbox(\"Selecione o target\", available_targets, index=default_target_index)\n",
        "\n",
        "X = df.drop(columns=[target_col,'region_id'])\n",
        "y = df[target_col]\n",
        "\n",
        "test_size = st.slider(\"Tamanho do conjunto de teste (%)\", 10, 50, 20) / 100\n",
        "random_state = st.number_input(\"Random State\", value=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=test_size, random_state=random_state\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# 2. Seleção do algoritmo\n",
        "# --------------------------\n",
        "st.subheader(\"Escolha o Algoritmo\")\n",
        "\n",
        "model_name = st.selectbox(\n",
        "    \"Modelo\",\n",
        "    [\n",
        "        \"Linear Regression\",\n",
        "        \"Random Forest\",\n",
        "        \"Gradient Boosting\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Hiperparâmetros\n",
        "if model_name == \"Random Forest\":\n",
        "    n_estimators = st.slider(\"Número de árvores\", 50, 500, 200)\n",
        "    max_depth = st.slider(\"Profundidade máxima\", 2, 30, 10)\n",
        "    model = RandomForestRegressor(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "elif model_name == \"Gradient Boosting\":\n",
        "    learning_rate = st.slider(\"Learning Rate\", 0.01, 0.5, 0.1)\n",
        "    n_estimators = st.slider(\"Número de estimadores\", 50, 500, 150)\n",
        "    model = GradientBoostingRegressor(\n",
        "        learning_rate=learning_rate,\n",
        "        n_estimators=n_estimators\n",
        "    )\n",
        "\n",
        "else:\n",
        "    model = LinearRegression()\n",
        "\n",
        "# --------------------------\n",
        "# 3. Treinar modelo\n",
        "# --------------------------\n",
        "if st.button(\"Treinar Modelo\"):\n",
        "    with st.spinner(\"Treinando...\"):\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # --------------------------\n",
        "        # 4. Mostrar métricas\n",
        "        # --------------------------\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        st.success(\"Treinamento Concluído!\")\n",
        "\n",
        "        st.subheader(\"Métricas\")\n",
        "        st.metric(\"MAE\", f\"{mae:.3f}\")\n",
        "        st.metric(\"RMSE\", f\"{rmse:.3f}\")\n",
        "        st.metric(\"R²\", f\"{r2:.3f}\")\n",
        "\n",
        "        # --------------------------\n",
        "        # 5. Plot Real vs Predito\n",
        "        # --------------------------\n",
        "        st.subheader(\"Real vs Predito\")\n",
        "\n",
        "        df_plot = pd.DataFrame({\n",
        "            \"Real\": y_test.values,\n",
        "            \"Predito\": y_pred\n",
        "        })\n",
        "\n",
        "        st.line_chart(df_plot)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3qlaLNB7NTis",
        "outputId": "ae6a841c-efd5-4ae8-b180-ceddbc488f5a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok.connect(addr=\"8501\")\n",
        "print(\"Acesse aqui:\", public_url)\n",
        "\n",
        "!streamlit run soybean_app.py --server.port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls7TYMnITAb0",
        "outputId": "b7b1426d-6868-469f-c806-bb02e20a0683"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acesse aqui: NgrokTunnel: \"https://presecular-yael-unavowably.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.16.145.219:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-12-05T21:39:26+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-ad3b1f8b-5379-4a1c-8a29-ec18d1217a82 acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "La3RX1qnTevQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}